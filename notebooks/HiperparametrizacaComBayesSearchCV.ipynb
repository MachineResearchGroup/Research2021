{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HiperparametrizacaComBayesSearchCV.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apDV_XePrIv-"
      },
      "source": [
        "<h1><b>Hiperparametrização com o algoritmo BayesSearchCV</b></h1>\n",
        "<p><b>Classificadores:</b>\n",
        "<ol>\n",
        "  <li>ExtraTree (ET)</li>\n",
        "  <li>Logistic regression (LR)</li>\n",
        "  <li>Multilayer Perceptron (MLP)</li>\n",
        "  <li>Multinomial Naive Bayes (MNB)</li>\n",
        "  <li>Passive Aggressive (PA)</li>\n",
        "  <li>Stochastic Gradient Descent (SGD)</li>\n",
        "  <li>Support Vector Machine (SVM)</li>\n",
        "</ol>\n",
        "<br><b>Base de dados:</b> PROMISE_exp.\n",
        "<br><b>Natureza do problema:</b> Hiperparametrização com validação cruzada, utilizando 11 subclasses de Requisitos Não-Funcionais (RNF) disponíveis na base de dados:</p>\n",
        "<table style=\"text-align:center;\" align=left>\n",
        "    <tr>\n",
        "        <th>Tipo de Requisito:</th>\n",
        "        <th>Classe:</th>\n",
        "        <th>Quantidade:</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Disponibilidade</td>\n",
        "        <td>A</td>\n",
        "        <td>31</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Tolerância à Falha</td>\n",
        "        <td>FT</td>\n",
        "        <td>18</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Legal</td>\n",
        "        <td>L</td>\n",
        "        <td>15</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Aparência</td>\n",
        "        <td>LF</td>\n",
        "        <td>49</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Manutenibilidade</td>\n",
        "        <td>MN</td>\n",
        "        <td>24</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Operacional</td>\n",
        "        <td>O</td>\n",
        "        <td>77</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Performance</td>\n",
        "        <td>PE</td>\n",
        "        <td>67</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Portabilidade</td>\n",
        "        <td>PO</td>\n",
        "        <td>12</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Escalabilidade</td>\n",
        "        <td>SC</td>\n",
        "        <td>22</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Segurança</td>\n",
        "        <td>SE</td>\n",
        "        <td>125</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Usabilidade</td>\n",
        "        <td>US</td>\n",
        "        <td>85</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Total:</td>\n",
        "        <td>11</td>\n",
        "        <td>525</td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agxv4NiEBwSk"
      },
      "source": [
        "<h4>Bibliotecas:</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyzm5fgbrIw5",
        "outputId": "a72109dc-d265-4f2b-abe3-f0dd8ee4a11e"
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import joblib\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "!pip install scikit-optimize\n",
        "from google.colab import drive\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.svm import SVC as SVM\n",
        "from scipy.sparse.csr import csr_matrix\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from sklearn.naive_bayes import MultinomialNB as MNB\n",
        "from sklearn.linear_model import SGDClassifier as SGD\n",
        "from sklearn.neural_network import MLPClassifier as MLP\n",
        "from sklearn.ensemble import ExtraTreesClassifier as ET\n",
        "from sklearn.linear_model import LogisticRegression as LR\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier as PA"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.8.1-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▎                            | 10 kB 23.3 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20 kB 32.1 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 30 kB 37.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40 kB 36.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 51 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 61 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 71 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 81 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 92 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 101 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.1)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-20.4.0-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (0.22.2.post1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-20.4.0 scikit-optimize-0.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr5N_akcD2fu",
        "outputId": "57a02812-00e8-4b93-8bfd-22c469a28c1f"
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "path_drive =  '/content/drive/MyDrive/CBIC/'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5x80qvBrIxM"
      },
      "source": [
        "<h3>Parâmetros e classificadores</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVXWIdYtBwSq"
      },
      "source": [
        "Clf_Prt = {}\n",
        "NomeClf = {}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XARH8d7aBwSr"
      },
      "source": [
        "<h4>ExtraTree (ET)</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHDuN0ynBwSs"
      },
      "source": [
        "parametros = {}\n",
        "parametros['n_estimators'] = Integer(150, 1100)\n",
        "parametros['criterion'] = Categorical(['gini', 'entropy'])\n",
        "parametros['max_depth'] = Integer(20, 120)\n",
        "parametros['min_samples_split'] = Integer(2,20)\n",
        "parametros['min_samples_leaf'] = [1]\n",
        "parametros['max_features'] = Categorical(['auto', 'sqrt', 'log2'])\n",
        "parametros['max_leaf_nodes'] = Integer(50, 150)\n",
        "parametros['warm_start'] = [True, False]\n",
        "parametros['max_samples'] = Real(0.1, 0.9)\n",
        "Clf_Prt[ET()] = parametros\n",
        "NomeClf[ET().__class__.__name__] = 'ET'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khBFXGuPBwSv"
      },
      "source": [
        "<h4>Logistic regression (LR)</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWBu0oMUBwSw"
      },
      "source": [
        "vet_param = []\n",
        "parametros = {}\n",
        "parametros['penalty'] = Categorical(['l2', 'none'])\n",
        "parametros['tol'] = Real(1e-5, 1e-3)\n",
        "parametros['C'] = Real(1e-1, 1.5)\n",
        "parametros['fit_intercept'] = [True, False]\n",
        "parametros['solver'] = Categorical(['newton-cg', 'lbfgs', 'sag', 'saga'])\n",
        "parametros['max_iter'] = Integer(100, 1000)\n",
        "parametros['multi_class'] = Categorical(['auto'])\n",
        "parametros['warm_start'] = [True, False]\n",
        "parametros['n_jobs'] = [-1]\n",
        "vet_param.append(parametros)\n",
        "\n",
        "parametros = {}\n",
        "parametros['penalty'] = ['elasticnet']\n",
        "parametros['tol'] = Real(1e-5, 1e-3)\n",
        "parametros['C'] = Real(1e-1, 1.5)\n",
        "parametros['fit_intercept'] = [True, False]\n",
        "parametros['solver'] = Categorical(['saga'])\n",
        "parametros['max_iter'] = Integer(100, 1000)\n",
        "parametros['multi_class'] = Categorical(['auto'])\n",
        "parametros['warm_start'] = [True, False]\n",
        "parametros['n_jobs'] = [-1]\n",
        "parametros['l1_ratio'] = Real(0, 1)\n",
        "vet_param.append(parametros)\n",
        "\n",
        "parametros = {}\n",
        "parametros['penalty'] = ['l1']\n",
        "parametros['tol'] = Real(1e-5, 1e-3)\n",
        "parametros['C'] = Real(1e-1, 1.5)\n",
        "parametros['intercept_scaling'] = Real(1e-3, 1e3)\n",
        "parametros['solver'] = Categorical(['liblinear', 'saga'])\n",
        "parametros['max_iter'] = Integer(100, 1000)\n",
        "parametros['multi_class'] = Categorical(['ovr'])\n",
        "parametros['warm_start'] = [True, False]\n",
        "vet_param.append(parametros)\n",
        "\n",
        "parametros = {}\n",
        "parametros['penalty'] = ['l2']\n",
        "parametros['dual'] = [True]\n",
        "parametros['tol'] = Real(1e-5, 1e-3)\n",
        "parametros['C'] = Real(1e-1, 1.5)\n",
        "parametros['fit_intercept'] = [True, False]\n",
        "parametros['solver'] = Categorical(['liblinear'])\n",
        "parametros['max_iter'] = Integer(100, 1000)\n",
        "parametros['multi_class'] = Categorical(['auto'])\n",
        "vet_param.append(parametros)\n",
        "\n",
        "Clf_Prt[LR()] = vet_param\n",
        "NomeClf[LR().__class__.__name__] = 'LR'"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oByprfbqcDUg"
      },
      "source": [
        "<h4>Multi-layer Perceptron (MLP)</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3HEst91cDUg"
      },
      "source": [
        "parametros = {}\n",
        "parametros['hidden_layer_sizes'] = Integer(20, 250)\n",
        "parametros['activation'] = Categorical(['tanh', 'relu'])\n",
        "parametros['solver'] = Categorical(['adam'])\n",
        "parametros['batch_size'] = Integer(32, 480)\n",
        "parametros['learning_rate_init'] = Real(1e-3, 0.1)\n",
        "parametros['validation_fraction'] = [0.1, 0.2]\n",
        "parametros['n_iter_no_change'] = [5, 10]\n",
        "parametros['early_stopping'] = [True]\n",
        "parametros['max_iter'] = Integer(20, 500)\n",
        "parametros['tol'] = Real(1e-5, 1e-3)\n",
        "parametros['warm_start'] = [True, False]\n",
        "Clf_Prt[MLP()] = parametros\n",
        "NomeClf[MLP().__class__.__name__] = 'MLP'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ko0OhMkC9-8"
      },
      "source": [
        "<h4>Multinomial Naive Bayes (MNB)</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjTbGHwQC9-9"
      },
      "source": [
        "parametros = {}\n",
        "parametros['alpha'] = Real(1e-5, 1e5)\n",
        "parametros['fit_prior'] = [True, False]\n",
        "Clf_Prt[MNB()] = parametros\n",
        "NomeClf[MNB().__class__.__name__] = 'MNB'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbgMeyxCnfxi"
      },
      "source": [
        "<h4>Passive Aggressive (PA)</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1D7-vW_ndhC"
      },
      "source": [
        "parametros = {}\n",
        "parametros['tol'] = Real(1e-5, 1e-3)\n",
        "parametros['C'] = Real(1e-2, 1e1)\n",
        "parametros['fit_intercept'] = [True, False]\n",
        "parametros['max_iter'] = Integer(20, 1000)\n",
        "parametros['early_stopping'] = [True]\n",
        "parametros['validation_fraction'] = [0.1, 0.2]\n",
        "parametros['n_iter_no_change'] = [5, 10]\n",
        "parametros['loss'] = ['hinge', 'squared_hinge']\n",
        "parametros['warm_start'] =[True, False]\n",
        "parametros['n_jobs'] = [-1]\n",
        "Clf_Prt[PA()] = parametros\n",
        "NomeClf[PA().__class__.__name__] = 'PA'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnQQzFvOBwS1"
      },
      "source": [
        "<h4>Stochastic Gradient Descent (SGD)</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiKdkJLIBwS2"
      },
      "source": [
        "parametros = {}\n",
        "parametros['loss'] = Categorical(['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'])\n",
        "parametros['penalty'] = Categorical(['l1', 'l2', 'elasticnet'])\n",
        "parametros['alpha'] = Real(1e-4, 1e-2)\n",
        "parametros['l1_ratio'] = Real(0, 1)\n",
        "parametros['fit_intercept'] = [True, False]\n",
        "parametros['max_iter'] = Integer(20, 1000)\n",
        "parametros['tol'] = Real(1e-5, 1e-3)\n",
        "parametros['shuffle'] = [True, False]\n",
        "parametros['epsilon'] = Real(1e-2, 1) \n",
        "parametros['n_jobs'] = [-1]\n",
        "parametros['learning_rate'] = Categorical(['optimal', 'invscaling', 'adaptive'])\n",
        "parametros['eta0'] = Real(1e-2, 1e1)\n",
        "parametros['power_t'] = Real(0, 0.1)\n",
        "parametros['early_stopping'] = [True]\n",
        "parametros['validation_fraction'] = [0.1, 0.2]\n",
        "parametros['n_iter_no_change'] = [5, 10]\n",
        "parametros['warm_start'] = [True, False]\n",
        "parametros['average'] = [True, False]\n",
        "Clf_Prt[SGD()] = parametros\n",
        "NomeClf[SGD().__class__.__name__] = 'SGD'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5qaHlRoBwS2"
      },
      "source": [
        "<h4>Support Vector Machine (SVM)</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRYFPES8rIxN"
      },
      "source": [
        "parametros = {}\n",
        "parametros['C'] = Real(1e-1, 1e2)\n",
        "parametros['kernel'] = Categorical(['linear', 'rbf'])\n",
        "parametros['degree']: Integer(2, 5)\n",
        "parametros['gamma'] = Categorical(['scale', 'auto'])\n",
        "parametros['shrinking'] = [True, False]\n",
        "parametros['probability'] = [True, False]\n",
        "parametros['tol'] = Real(1e-5, 1e-3)\n",
        "parametros['cache_size'] = [500]\n",
        "parametros['decision_function_shape'] = Categorical(['ovo', 'ovr'])\n",
        "Clf_Prt[SVM()] = parametros\n",
        "NomeClf[SVM().__class__.__name__] = 'SVM'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4Ze7PI6VJp_"
      },
      "source": [
        "<h4>Time Monitoring</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0xfNWQ1VJp_"
      },
      "source": [
        "class timeTool():\n",
        "    import time\n",
        "    iniTime = 0.0\n",
        "    finalTime = 0.0\n",
        "    totalTime = '00h00m00s'\n",
        "    endDataTime = 'Date Hour year'\n",
        "    initDataTime = 'Date Hour year'\n",
        "    def init(self):\n",
        "        self.iniTime = self.time.time()\n",
        "        self.initDataTime = self.time.ctime()\n",
        "    def end(self):\n",
        "        self.finalTime = self.time.time()\n",
        "        self.endDataTime = self.time.ctime()\n",
        "        hour = 0 \n",
        "        minute = 0 \n",
        "        second = 0\n",
        "        value = self.finalTime - self.iniTime\n",
        "        if value >= 3600:\n",
        "            hour = int(value/3600)\n",
        "            helper = value%3600\n",
        "            if helper >= 60:\n",
        "                minute = int(helper/60)\n",
        "                second = int(helper%60)\n",
        "            else:\n",
        "                second = int(helper)\n",
        "            self.totalTime = '{0}h:{1}m:{2}s'.format(hour, minute, second)\n",
        "        elif value >= 60:\n",
        "            minute = int(value/60)\n",
        "            second = int(value%60)\n",
        "            self.totalTime = '{0}h:{1}m:{2}s'.format(hour, minute, second)\n",
        "        else:\n",
        "            second = int(value)\n",
        "            self.totalTime = '{0}h:{1}m:{2}s'.format(hour, minute, second)\n",
        "    def getExecuTime(self):\n",
        "        return self.totalTime\n",
        "    def getInDateTime(self):\n",
        "        return self.initDataTime\n",
        "    def getEnDataTime(self):\n",
        "        return self.endDataTime"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1xlh5LZBwS3",
        "outputId": "1e42045b-1061-471e-9775-1ad87f440197"
      },
      "source": [
        "<h3>Hiperparametrização:</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Apyk34bkiyr"
      },
      "source": [
        "resamplings = ['origin', 'tomek', 'adasyn', 'smote', 'bdsmote', 'smotetomek']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcV5kKX-kdGM"
      },
      "source": [
        "def load_sparse_csr(filename):\n",
        "    loader = np.load(filename)\n",
        "    return csr_matrix((loader['data'], loader['indices'], loader['indptr']), shape=loader['shape'])\n",
        "\n",
        "\n",
        "def get_data(resampling, n_intr, n_data):\n",
        "    train_tfidf = load_sparse_csr(path_drive+'datasets/data_'+str(n_intr)+'/train/'+resampling + '_train(' + str(n_data) + ').npz')\n",
        "    train_class = pd.read_csv(path_drive+'datasets/data_'+str(n_intr)+'/train/'+resampling + '_train(' + str(n_data) + ').csv')\n",
        "\n",
        "    return train_tfidf, train_class"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNVYeEjGKCHY"
      },
      "source": [
        "def create_path(path_name):\n",
        "  if not os.path.isdir(path_drive+path_name):\n",
        "    os.mkdir(path_drive+path_name)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oui4bEJxBwS3",
        "outputId": "96b003c9-d401-4d7f-ea2c-743b844ba28c"
      },
      "source": [
        "iterations = 1\n",
        "folds = 1\n",
        "n_splits = 1\n",
        "n_iter = 1\n",
        "\n",
        "create_path('hyperparametrization/')\n",
        "for i in range(iterations):\n",
        "    create_path('hyperparametrization/data_'+str(i+1)+'/')\n",
        "    for j in range(folds):\n",
        "        print(\"\\nInteration \"+str(i+1), \"Dobra \"+str(j+1))\n",
        "        for resample in resamplings:\n",
        "            create_path('hyperparametrization/data_'+str(i+1)+'/'+resample+'/')\n",
        "\n",
        "            X_Tokens, train_class = get_data(resample, i+1, j+1)\n",
        "            y_Class = np.array(train_class['Class'])\n",
        "            warnings.filterwarnings('ignore')\n",
        "\n",
        "            cv = ShuffleSplit(n_splits=n_splits, test_size=0.2)\n",
        "\n",
        "            for classificador in Clf_Prt:\n",
        "                modelName = classificador.__class__.__name__\n",
        "                timeT = timeTool()\n",
        "                timeT.init()\n",
        "                print('\\nStart of the ' + modelName + ' algorithm with ' + resample + ' at ' + timeT.getInDateTime())\n",
        "                modelo = BayesSearchCV(estimator=classificador, search_spaces=Clf_Prt[classificador], \n",
        "                                       n_iter=n_iter, scoring='f1_macro', cv=cv, refit=True, return_train_score=False, n_jobs=3, n_points=3, pre_dispatch=3)\n",
        "\n",
        "                modelo.fit(X_Tokens, y_Class)\n",
        "                timeT.end()\n",
        "\n",
        "                #Salvando modelo\n",
        "                clf = modelo.best_estimator_\n",
        "                create_path('hyperparametrization/data_'+str(i+1)+'/'+resample+'/models/')\n",
        "                filename = path_drive+'hyperparametrization/data_'+str(i+1)+'/'+resample+'/models/'+clf.__class__.__name__+'('+str(j+1)+').joblib.pkl'\n",
        "                _ = joblib.dump(clf, filename, compress=9)\n",
        "\n",
        "                #Tratamento dos resultados:\n",
        "                dt = pd.DataFrame(modelo.cv_results_)\n",
        "                linhas = {'Algorithm': NomeClf[modelName],\n",
        "                          'DataSample': resample+'_'+str(j+1), \n",
        "                          'n_inter': modelo.n_iter, 'n_div': modelo.n_splits_, 'Initial Date/Hour': timeT.getInDateTime(), \n",
        "                          'Final Date/Hour': timeT.getEnDataTime(), 'Execution time': timeT.getExecuTime(),\n",
        "                          'f1-score Macro': '{:.0%}'.format(modelo.best_score_), 'Params': modelo.best_params_}\n",
        "                path = path_drive+'hyperparametrization/data_'+str(i+1)+'/'+resample+'/hypeResults'+modelo.__class__.__name__+'('+NomeClf[modelName] +').csv'\n",
        "                try:\n",
        "                    open(path, 'r')\n",
        "                    with open(path, 'a') as arq:\n",
        "                        writer = csv.writer(arq)\n",
        "                        writer.writerow(linhas.values())\n",
        "                except IOError:\n",
        "                    dataF = pd.DataFrame(columns=linhas.keys())\n",
        "                    dataF = dataF.append(linhas, ignore_index=True)\n",
        "                    dataF.to_csv(path, index=False)\n",
        "                print('End of the ' + modelName + ' algorithm with ' + resample + ' at ' + timeT.getInDateTime() + '\\nTotal run time: ' + timeT.getExecuTime())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Interation 1 Dobra 1\n",
            "\n",
            "Start of the PassiveAggressiveClassifier algorithm with origin at Sun Aug  8 00:35:16 2021\n",
            "End of the PassiveAggressiveClassifier algorithm with origin at Sun Aug  8 00:35:16 2021\n",
            "Total run time: 0h:0m:0s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}